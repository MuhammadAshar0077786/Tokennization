# -*- coding: utf-8 -*-
"""Token.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pUNviFc4Nd548QSweEOtm0B_ihCIOKXe
"""

def characterConverter():
  lista = []
  for i in str(input()):
    if i == 'z':
      lista.append('a')
    elif i == 'Z':
      lista.append('A')
    else:
      lista.append(chr(ord(i)+1))
  print(lista)
characterConverter()

import datatable as dt

# import numpy as np
# data_30_days_random = np.random.randint(10,50,30)
# days = [j for j in range(30)]
# data_30_days_random = [i for i in data_30_days_random]
# combined = list(enumerate(data_30_days_random))


# df = pd.DataFrame(combined, columns=["day", "random_value"])
# X = df.iloc[:,0]
# y = df.iloc[:,1]

# from sklearn.model_selection import train_test_split as tts
# X_train, X_test, y_train, y_test = tts(X, y, test_size=.2)

from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit([X_train], [y_train])
prediction = model.predict([y_test])

import numpy as np
np.random.randint(10,50,5)
years = np.linspace(2021,2031,11)
sales = np.random.randint(1,10,10)
randomsales = [(years[i],sales[i]) for i in range(10)]
randomsales

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

file = pd.read_excel('Sample - Superstore.xls')
file.head()

file.describe()

file.info()

# print(file.loc[:,"Product Name"].value_counts()) # some things are sold only onces while some are sold 48 times
# print(len(file.loc[:,"Product Name"].unique())) # there are 1850 products
# file.isna().sum() # there do not appear any null or empty cell
test_values = ["", " ", "-", "_", "?", "U", "u", "NAn", "NA"]

a = "hello world this is jawad"

a.split()

from nltk import sent_tokenize as tokenize
tokenize(a)

nltk.pos_tag(a.split())

# nltk.download('averaged_perceptron_tagger')
nltk.download('punkt')

s = "Everything is all about money"
k = "it originated from the idea that thre arereaders who prefer learning new skills from the comfort of their drawing rooms"

# NLTK tokenizer used
tokenize(k)

# using python built in funtion to tokenize
s.split()

from nltk.corpus import stopwords
stop_words = set(stopwords.words('english'))

nltk.download('stopwords')

W = [w for w in k if w not in stop_words]

# tagging without stop words
tags = nltk.pos_tag(W)

